1. Text Clusteting: The firt part in the process is to get familiarized with the text clusteting approach using LLM's
2. For example let's take a dataset which has abstracts from various research papers.
3. In order to have better understanding from these dataset, clustering can help.
4. Step 1: Use LLM to create embedding from the data
   Step 2: The obtained embedding if high in dimensionality (which will be the case) can be brought to the lower dimension using dimensionality reduction techniques
   Step 3: Output form step 2 is passed to a clustering algorithm that can create clusters
5. Choice of Dimensionality Reduction techniques: While PCA is a popular technique we use a similar yet slightly different technique of dimensionality reduction called as UMAP
6. UMAP works by projecting data points from a higher-dimensional space to a lower-dimensional space, prioritizing the preservation of local structure while attempting to retain as much global structure as possible
7. For the context of this book we have used Hierarchical clustering technique which is HDBSCAN.
   HDBSCAN Working: A. Assumes each data point to be a single cluster to start with
                    B. Uses bottom to top approach of combining data points to one cluster
                    C. Each points are comibined based on the maximum rechability distance
                    D. maximum rechability distance is defined as the max of Core distance and distance betweeen two points
                    E. Core distance is the distance between given point and Nth nearest neighbors termed as MinPts.
                    F. Clusters are then pruned based on how "stable" each of these clusters are
                    G. Stability of clustered is deterimed using varying thresholds of lambda which is the inverse of core distance
                    H. Core idea here is irrespective of varying thresholds if the clusters tends to appear then it re-affirms the existence of these clusters

  

